Namespace(accumulation_steps=None, amp_opt_level='O1', base_lr=0.05, batch_size=24, cache_mode='part', dataset='Synapse', deterministic=1, eval=False, img_size=224, list_dir='/home/students/yiwei/yiwei_gitlab/MISSFormer-bridge/MISSFormer/lists/lists_Synapse', max_epochs=400, max_iterations=90000, n_gpu=1, num_classes=9, opts=None, output_dir='/home/students/yiwei/yiwei_gitlab/MISSFormer-bridge/MISSFormer/outputs', resume=None, root_path='/images/PublicDataset/Transunet_synaps/project_TransUNet/data/Synapse/train_npz', seed=1234, tag=None, throughput=False, use_checkpoint=False, zip=False)
The length of train set is: 2211
93 iterations per epoch. 37200 max iterations 
iteration 1 : loss : 1.597859, loss_ce: 2.589200
iteration 2 : loss : 1.132149, loss_ce: 1.473024
iteration 3 : loss : 0.819097, loss_ce: 0.765533
iteration 4 : loss : 0.648104, loss_ce: 0.315614
iteration 5 : loss : 0.613604, loss_ce: 0.210232
iteration 6 : loss : 0.625544, loss_ce: 0.233047
iteration 7 : loss : 0.653744, loss_ce: 0.300651
iteration 8 : loss : 0.673456, loss_ce: 0.348461
iteration 9 : loss : 0.648075, loss_ce: 0.285467
iteration 10 : loss : 0.659073, loss_ce: 0.312242
iteration 11 : loss : 0.690234, loss_ce: 0.389743
iteration 12 : loss : 0.638659, loss_ce: 0.262024
iteration 13 : loss : 0.629662, loss_ce: 0.240286
iteration 14 : loss : 0.680895, loss_ce: 0.368745
iteration 15 : loss : 0.620305, loss_ce: 0.223928
iteration 16 : loss : 0.614796, loss_ce: 0.228846
iteration 17 : loss : 0.675646, loss_ce: 0.416493
iteration 18 : loss : 0.656897, loss_ce: 0.386220
iteration 19 : loss : 0.637412, loss_ce: 0.293819
iteration 20 : loss : 0.655288, loss_ce: 0.315221
iteration 21 : loss : 0.607777, loss_ce: 0.205196
iteration 22 : loss : 0.639560, loss_ce: 0.286842
iteration 23 : loss : 0.641743, loss_ce: 0.291005
iteration 24 : loss : 0.579845, loss_ce: 0.178100
iteration 25 : loss : 0.578368, loss_ce: 0.198270
iteration 26 : loss : 0.591626, loss_ce: 0.238684
iteration 27 : loss : 0.613481, loss_ce: 0.268102
iteration 28 : loss : 0.613341, loss_ce: 0.269836
iteration 29 : loss : 0.622888, loss_ce: 0.275893
iteration 30 : loss : 0.591684, loss_ce: 0.202910
iteration 31 : loss : 0.612469, loss_ce: 0.273059
iteration 32 : loss : 0.654600, loss_ce: 0.356133
iteration 33 : loss : 0.570347, loss_ce: 0.158976
iteration 34 : loss : 0.608285, loss_ce: 0.243094
iteration 35 : loss : 0.593702, loss_ce: 0.207917
iteration 36 : loss : 0.570562, loss_ce: 0.154346
iteration 37 : loss : 0.618622, loss_ce: 0.304382
iteration 38 : loss : 0.619599, loss_ce: 0.275748
iteration 39 : loss : 0.603702, loss_ce: 0.282587
iteration 40 : loss : 0.585000, loss_ce: 0.202547
iteration 41 : loss : 0.578370, loss_ce: 0.215305
iteration 42 : loss : 0.619166, loss_ce: 0.288408
iteration 43 : loss : 0.607219, loss_ce: 0.260924
iteration 44 : loss : 0.608869, loss_ce: 0.253759
iteration 45 : loss : 0.649183, loss_ce: 0.371970
iteration 46 : loss : 0.602812, loss_ce: 0.257539
iteration 47 : loss : 0.597134, loss_ce: 0.235470
iteration 48 : loss : 0.583689, loss_ce: 0.204442
iteration 49 : loss : 0.646245, loss_ce: 0.360475
iteration 50 : loss : 0.573862, loss_ce: 0.200900
iteration 51 : loss : 0.581368, loss_ce: 0.201576
iteration 52 : loss : 0.583175, loss_ce: 0.203150
iteration 53 : loss : 0.590463, loss_ce: 0.214506
iteration 54 : loss : 0.618073, loss_ce: 0.284217
iteration 55 : loss : 0.568383, loss_ce: 0.154414
iteration 56 : loss : 0.576113, loss_ce: 0.210782
iteration 57 : loss : 0.620574, loss_ce: 0.277539
iteration 58 : loss : 0.576710, loss_ce: 0.186185
iteration 59 : loss : 0.594871, loss_ce: 0.222297
iteration 60 : loss : 0.604349, loss_ce: 0.244622
iteration 61 : loss : 0.583033, loss_ce: 0.222363
iteration 62 : loss : 0.585388, loss_ce: 0.220795
iteration 63 : loss : 0.609718, loss_ce: 0.230889
iteration 64 : loss : 0.617847, loss_ce: 0.322042
iteration 65 : loss : 0.595683, loss_ce: 0.267293
iteration 66 : loss : 0.577509, loss_ce: 0.203389
iteration 67 : loss : 0.595275, loss_ce: 0.245975
iteration 68 : loss : 0.579965, loss_ce: 0.197455
iteration 69 : loss : 0.596686, loss_ce: 0.245208
iteration 70 : loss : 0.616813, loss_ce: 0.292316
iteration 71 : loss : 0.581250, loss_ce: 0.210295
iteration 72 : loss : 0.585315, loss_ce: 0.206632
iteration 73 : loss : 0.638479, loss_ce: 0.312049
iteration 74 : loss : 0.559143, loss_ce: 0.145871
iteration 75 : loss : 0.608459, loss_ce: 0.250482
iteration 76 : loss : 0.588153, loss_ce: 0.178123
iteration 77 : loss : 0.604449, loss_ce: 0.268150
iteration 78 : loss : 0.594040, loss_ce: 0.232288
iteration 79 : loss : 0.564332, loss_ce: 0.176202
iteration 80 : loss : 0.692392, loss_ce: 0.506005
iteration 81 : loss : 0.590188, loss_ce: 0.234051
iteration 82 : loss : 0.601533, loss_ce: 0.252251
iteration 83 : loss : 0.582227, loss_ce: 0.217015
iteration 84 : loss : 0.636092, loss_ce: 0.325608
iteration 85 : loss : 0.637310, loss_ce: 0.328156
iteration 86 : loss : 0.646480, loss_ce: 0.328584
iteration 87 : loss : 0.539291, loss_ce: 0.136668
iteration 88 : loss : 0.609052, loss_ce: 0.274836
iteration 89 : loss : 0.653148, loss_ce: 0.347440
iteration 90 : loss : 0.589922, loss_ce: 0.204507
iteration 91 : loss : 0.594053, loss_ce: 0.223229
iteration 92 : loss : 0.601526, loss_ce: 0.245899
iteration 93 : loss : 0.624534, loss_ce: 0.398347
iteration 94 : loss : 0.585608, loss_ce: 0.208682
iteration 95 : loss : 0.617473, loss_ce: 0.305087
iteration 96 : loss : 0.585669, loss_ce: 0.200167
iteration 97 : loss : 0.587704, loss_ce: 0.190310
iteration 98 : loss : 0.564862, loss_ce: 0.149205
iteration 99 : loss : 0.620395, loss_ce: 0.289776
iteration 100 : loss : 0.575345, loss_ce: 0.157199
iteration 101 : loss : 0.611728, loss_ce: 0.288795
iteration 102 : loss : 0.596402, loss_ce: 0.250240
iteration 103 : loss : 0.596018, loss_ce: 0.254501
iteration 104 : loss : 0.599856, loss_ce: 0.264602
iteration 105 : loss : 0.579814, loss_ce: 0.187641
iteration 106 : loss : 0.604306, loss_ce: 0.259281
iteration 107 : loss : 0.599569, loss_ce: 0.240435
iteration 108 : loss : 0.606582, loss_ce: 0.268831
iteration 109 : loss : 0.581995, loss_ce: 0.219542
iteration 110 : loss : 0.555792, loss_ce: 0.209630
iteration 111 : loss : 0.583533, loss_ce: 0.203406
iteration 112 : loss : 0.586786, loss_ce: 0.193284
iteration 113 : loss : 0.588002, loss_ce: 0.183620
iteration 114 : loss : 0.573856, loss_ce: 0.192233
iteration 115 : loss : 0.610606, loss_ce: 0.258410
iteration 116 : loss : 0.561364, loss_ce: 0.155682
iteration 117 : loss : 0.562316, loss_ce: 0.149132
iteration 118 : loss : 0.557791, loss_ce: 0.194347
iteration 119 : loss : 0.532975, loss_ce: 0.155273
iteration 120 : loss : 0.587626, loss_ce: 0.265078
iteration 121 : loss : 0.567067, loss_ce: 0.191383
iteration 122 : loss : 0.592729, loss_ce: 0.227788
iteration 123 : loss : 0.571177, loss_ce: 0.213729
iteration 124 : loss : 0.615353, loss_ce: 0.251157
iteration 125 : loss : 0.578036, loss_ce: 0.196222
iteration 126 : loss : 0.544005, loss_ce: 0.149169
iteration 127 : loss : 0.596722, loss_ce: 0.269696
iteration 128 : loss : 0.623991, loss_ce: 0.323792
iteration 129 : loss : 0.584432, loss_ce: 0.249918
iteration 130 : loss : 0.580952, loss_ce: 0.222835
iteration 131 : loss : 0.611841, loss_ce: 0.301420
iteration 132 : loss : 0.579325, loss_ce: 0.197683
iteration 133 : loss : 0.632465, loss_ce: 0.289472
iteration 134 : loss : 0.559537, loss_ce: 0.176542
iteration 135 : loss : 0.543631, loss_ce: 0.142461
iteration 136 : loss : 0.595563, loss_ce: 0.260859
iteration 137 : loss : 0.584280, loss_ce: 0.227206
iteration 138 : loss : 0.585177, loss_ce: 0.221764
iteration 139 : loss : 0.619673, loss_ce: 0.315186
iteration 140 : loss : 0.601437, loss_ce: 0.308329
iteration 141 : loss : 0.611290, loss_ce: 0.287908
iteration 142 : loss : 0.589189, loss_ce: 0.274963
iteration 143 : loss : 0.599920, loss_ce: 0.242981
iteration 144 : loss : 0.586609, loss_ce: 0.226211
iteration 145 : loss : 0.579811, loss_ce: 0.191028
iteration 146 : loss : 0.577212, loss_ce: 0.195805
iteration 147 : loss : 0.569122, loss_ce: 0.199135
iteration 148 : loss : 0.582946, loss_ce: 0.233916
iteration 149 : loss : 0.554693, loss_ce: 0.203006
iteration 150 : loss : 0.574894, loss_ce: 0.223831
iteration 151 : loss : 0.557496, loss_ce: 0.227678
iteration 152 : loss : 0.551254, loss_ce: 0.171598
iteration 153 : loss : 0.621090, loss_ce: 0.292028
iteration 154 : loss : 0.529481, loss_ce: 0.140994
iteration 155 : loss : 0.570887, loss_ce: 0.208285
iteration 156 : loss : 0.545823, loss_ce: 0.202544
iteration 157 : loss : 0.616794, loss_ce: 0.322667
iteration 158 : loss : 0.585131, loss_ce: 0.224679
iteration 159 : loss : 0.588369, loss_ce: 0.265482
iteration 160 : loss : 0.575764, loss_ce: 0.219135
iteration 161 : loss : 0.565507, loss_ce: 0.199899
iteration 162 : loss : 0.574018, loss_ce: 0.223596
iteration 163 : loss : 0.578292, loss_ce: 0.230060
iteration 164 : loss : 0.610057, loss_ce: 0.287404
iteration 165 : loss : 0.577868, loss_ce: 0.175572
iteration 166 : loss : 0.565009, loss_ce: 0.167207
iteration 167 : loss : 0.567494, loss_ce: 0.191242
iteration 168 : loss : 0.592661, loss_ce: 0.227242
iteration 169 : loss : 0.601763, loss_ce: 0.288049
iteration 170 : loss : 0.578285, loss_ce: 0.229419
iteration 171 : loss : 0.586632, loss_ce: 0.271794
iteration 172 : loss : 0.573189, loss_ce: 0.192057
iteration 173 : loss : 0.548450, loss_ce: 0.170201
iteration 174 : loss : 0.559207, loss_ce: 0.180598
iteration 175 : loss : 0.575272, loss_ce: 0.165268
iteration 176 : loss : 0.618457, loss_ce: 0.254087
iteration 177 : loss : 0.558089, loss_ce: 0.192034
iteration 178 : loss : 0.596278, loss_ce: 0.261082
iteration 179 : loss : 0.539291, loss_ce: 0.155375
iteration 180 : loss : 0.573827, loss_ce: 0.230895
iteration 181 : loss : 0.575410, loss_ce: 0.239851
iteration 182 : loss : 0.561497, loss_ce: 0.116364
iteration 183 : loss : 0.513875, loss_ce: 0.104354
iteration 184 : loss : 0.622489, loss_ce: 0.273753
iteration 185 : loss : 0.558826, loss_ce: 0.199503
iteration 186 : loss : 0.546752, loss_ce: 0.038387
iteration 187 : loss : 0.539754, loss_ce: 0.119014
iteration 188 : loss : 0.556409, loss_ce: 0.221039
iteration 189 : loss : 0.590021, loss_ce: 0.209233
iteration 190 : loss : 0.626124, loss_ce: 0.373086
iteration 191 : loss : 0.594573, loss_ce: 0.255055
iteration 192 : loss : 0.549639, loss_ce: 0.202865
iteration 193 : loss : 0.550782, loss_ce: 0.176191
iteration 194 : loss : 0.546499, loss_ce: 0.162562
iteration 195 : loss : 0.544536, loss_ce: 0.149380
iteration 196 : loss : 0.569495, loss_ce: 0.186660
iteration 197 : loss : 0.560188, loss_ce: 0.131206
iteration 198 : loss : 0.605842, loss_ce: 0.252003
iteration 199 : loss : 0.545321, loss_ce: 0.147707
iteration 200 : loss : 0.575037, loss_ce: 0.228462
iteration 201 : loss : 0.599531, loss_ce: 0.266460
iteration 202 : loss : 0.569050, loss_ce: 0.164675
iteration 203 : loss : 0.593739, loss_ce: 0.232086
iteration 204 : loss : 0.557093, loss_ce: 0.180960
iteration 205 : loss : 0.543473, loss_ce: 0.144317
iteration 206 : loss : 0.548863, loss_ce: 0.163308
iteration 207 : loss : 0.589023, loss_ce: 0.258896
iteration 208 : loss : 0.568895, loss_ce: 0.196404
iteration 209 : loss : 0.540232, loss_ce: 0.143033
iteration 210 : loss : 0.547222, loss_ce: 0.165139
iteration 211 : loss : 0.546257, loss_ce: 0.128049
iteration 212 : loss : 0.552837, loss_ce: 0.152353
iteration 213 : loss : 0.555063, loss_ce: 0.148964
iteration 214 : loss : 0.550807, loss_ce: 0.175634
iteration 215 : loss : 0.530676, loss_ce: 0.120056
iteration 216 : loss : 0.581918, loss_ce: 0.231234
iteration 217 : loss : 0.568478, loss_ce: 0.254665
iteration 218 : loss : 0.547551, loss_ce: 0.187923
iteration 219 : loss : 0.571434, loss_ce: 0.220649
iteration 220 : loss : 0.578913, loss_ce: 0.254105
iteration 221 : loss : 0.550236, loss_ce: 0.149634
iteration 222 : loss : 0.590213, loss_ce: 0.279117
iteration 223 : loss : 0.604575, loss_ce: 0.313209
iteration 224 : loss : 0.525854, loss_ce: 0.135461
iteration 225 : loss : 0.564309, loss_ce: 0.229146
iteration 226 : loss : 0.560192, loss_ce: 0.237079
iteration 227 : loss : 0.545539, loss_ce: 0.150530
iteration 228 : loss : 0.575404, loss_ce: 0.164309
iteration 229 : loss : 0.550885, loss_ce: 0.180209
iteration 230 : loss : 0.581578, loss_ce: 0.214268
iteration 231 : loss : 0.575645, loss_ce: 0.251079
iteration 232 : loss : 0.580099, loss_ce: 0.213449
iteration 233 : loss : 0.590232, loss_ce: 0.298283
iteration 234 : loss : 0.578458, loss_ce: 0.288821
iteration 235 : loss : 0.601629, loss_ce: 0.314094
iteration 236 : loss : 0.568584, loss_ce: 0.239791
iteration 237 : loss : 0.553420, loss_ce: 0.154694
iteration 238 : loss : 0.623056, loss_ce: 0.309822
iteration 239 : loss : 0.556327, loss_ce: 0.214105
iteration 240 : loss : 0.554484, loss_ce: 0.159002
iteration 241 : loss : 0.578861, loss_ce: 0.211106
iteration 242 : loss : 0.549836, loss_ce: 0.145884
iteration 243 : loss : 0.580173, loss_ce: 0.224195
iteration 244 : loss : 0.600517, loss_ce: 0.237786
iteration 245 : loss : 0.571665, loss_ce: 0.231429
iteration 246 : loss : 0.569320, loss_ce: 0.245835
iteration 247 : loss : 0.593572, loss_ce: 0.263238
iteration 248 : loss : 0.594542, loss_ce: 0.273532
iteration 249 : loss : 0.534515, loss_ce: 0.144855
iteration 250 : loss : 0.581504, loss_ce: 0.270886
iteration 251 : loss : 0.542512, loss_ce: 0.183998
iteration 252 : loss : 0.520706, loss_ce: 0.115211
iteration 253 : loss : 0.552098, loss_ce: 0.171581
iteration 254 : loss : 0.560527, loss_ce: 0.200239
iteration 255 : loss : 0.562610, loss_ce: 0.201941
iteration 256 : loss : 0.557944, loss_ce: 0.172149
iteration 257 : loss : 0.573146, loss_ce: 0.207867
iteration 258 : loss : 0.545259, loss_ce: 0.190056
iteration 259 : loss : 0.551966, loss_ce: 0.177745
iteration 260 : loss : 0.544542, loss_ce: 0.134165
iteration 261 : loss : 0.568626, loss_ce: 0.185867
iteration 262 : loss : 0.580965, loss_ce: 0.228032
iteration 263 : loss : 0.599425, loss_ce: 0.257168
iteration 264 : loss : 0.577362, loss_ce: 0.183114
iteration 265 : loss : 0.611343, loss_ce: 0.303574
